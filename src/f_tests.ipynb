{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import h5py\n",
    "from model import LSTM_ManyToOne\n",
    "from utils import calc_accuracy,eval_help,eval_variable_help\n",
    "from dataloader import Data_Query\n",
    "import parameters as par\n",
    "import faiss\n",
    "import tqdm\n",
    "torch.cuda.set_device(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(par.ROOT_DIR, \"splits/Shopping100k/imgs_test.txt\")) as f:\n",
    "            img_data = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gallery_feat=np.load(par.FEAT_TEST_SENZA_N)\n",
    "test_labels = np.loadtxt(os.path.join(par.ROOT_DIR,par.LABEL_TEST), dtype=int)\n",
    "path=par.DATA_TEST\n",
    "Data_test = h5py.File(path)\n",
    "t_id=Data_test['t']#id del target \n",
    "query_labels=test_labels[t_id]\n",
    "test_data=Data_Query(Data_test=Data_test,gallery_feat=gallery_feat,label_data=test_labels,N=par.N)\n",
    "gallery_loader=torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False,\n",
    "                                        sampler=torch.utils.data.SequentialSampler(test_data),\n",
    "                                            drop_last=False)\n",
    "\n",
    "model=LSTM_ManyToOne(input_size=151,seq_len=par.N,output_size=4080,hidden_dim=4080,n_layers=par.NUM_LAYER,drop_prob=0.5)\n",
    "last_train=par.MODEL_EVAL\n",
    "path_pretrained_model=os.path.join(par.LOG_DIR,\"{last_train}/best_model.pkl\".format(last_train=last_train))\n",
    "#load_pretrained_model\n",
    "model.load_state_dict(torch.load(path_pretrained_model))\n",
    "model.cuda()\n",
    "if (par.Eval_variable_legnth):\n",
    "    predicted_tfeat=eval_variable_help(model,gallery_loader)\n",
    "else:\n",
    "    predicted_tfeat= eval_help(model,gallery_loader)\n",
    "\n",
    "log_dir=os.path.join(par.LOG_DIR,\"log_eval.txt\")\n",
    "#evaluate the top@k results\n",
    "dim = 4080  # dimension\n",
    "database = gallery_feat\n",
    "queries = predicted_tfeat# Dipende dallo step di tempo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "print(\"N is :\",par.N)\n",
    "num_database = database.shape[0]\n",
    "num_query = queries.shape[0]\n",
    "print(\"Step:{s} ,Num of image in database is {n1}, Num of query img is {n2}\".format(s=par.N,n1=num_database,n2=num_query))\n",
    "\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(database)\n",
    "_, knn = index.search(queries, k)\n",
    "assert (query_labels.shape[0] == queries.shape[0])\n",
    "num_foto=0\n",
    "hits = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "im1=os.path.join(par.ROOT_DIR,\"dati/Images/Female/4_Shirts_blouses/0045884_16.jpg\")\n",
    "# read images from computer\n",
    "\n",
    "import matplotlib.ticker as plticker\n",
    "try:\n",
    "    from PIL import Image,ImageOps\n",
    "except ImportError:\n",
    "    import Image,ImageOps\n",
    "\n",
    "\n",
    "def plt_imges(imgs,inx,id):\n",
    "    image = Image.open(imgs[0])\n",
    "    my_dpi=300\n",
    "    fig=plt.figure(figsize=(float(image.size[0])/my_dpi,float(image.size[1])/my_dpi),dpi=my_dpi)\n",
    "    f, axarr = plt.subplots(1,11)\n",
    "   \n",
    "    for i in range(len(imgs)):\n",
    "        image = Image.open(imgs[i])\n",
    "        if(i==inx):\n",
    "            image = ImageOps.expand(image,border=30,fill='black')\n",
    "        axarr[i].axis('off')\n",
    "        axarr[i].imshow(image)\n",
    "    path=\"/andromeda/shared/reco-pomigliano/fashion/disentagledFeaturesExtractor/log/Img_results/{id}.png\".format(id=id)\n",
    "    plt.savefig(path)\n",
    "        \n",
    "plt_imges([im1,im1,im1,im1,im1,im1],3,5)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits=0\n",
    "tq=range(num_query)\n",
    "for q in tq: # itera i dati predicted_tfeat\n",
    "    neighbours_idxs = knn[q]# gli indici dei k-feat pi√π simili alla predicted_tfeat[q]\n",
    "    imgs=[os.path.join(par.ROOT_DIR,\"dati/Images/\",img_data[q])]\n",
    "    count=0\n",
    "    found=False\n",
    "    index_im=0\n",
    "    for n_idx in neighbours_idxs:\n",
    "        imgs.append(os.path.join(par.ROOT_DIR,\"dati/Images/\",img_data[n_idx]))\n",
    "        if (test_labels[n_idx] == query_labels[q]).all():\n",
    "            hits += 1\n",
    "            found=True\n",
    "            index_im=count+1\n",
    "            print(count)\n",
    "            \n",
    "        count=count+1\n",
    "    if(found):\n",
    "        plt_imges(imgs,index_im,q)\n",
    "    \n",
    "    #tq.set_description(\"Num of hit {h}\".format(h=hits))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adde-m",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13 (default, Mar 29 2022, 02:18:16) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f89d0e194b439387b5e186bf81e2159fc102e5b3337f084ca54f84cec4c12f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
